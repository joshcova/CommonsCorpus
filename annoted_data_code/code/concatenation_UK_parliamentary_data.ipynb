{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f23b804",
   "metadata": {},
   "source": [
    "After having annotated all parliamentary speeches with the metadata contained in the Comparative Legislators Database (CLD), we can now concatenate all the data from the different decades, standardize the nomenclature and divide them into different dataframes for each legislature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b504da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd1eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1970s = pd.read_pickle(\"./output_1970s.pkl\")\n",
    "df_1980s = pd.read_pickle(\"./output_1980s.pkl\")\n",
    "df_1990s = pd.read_pickle(\"./output_1990s.pkl\")  \n",
    "df_2000s = pd.read_pickle(\"./output_2000s.pkl\")\n",
    "df_2010_2015 = pd.read_pickle(\"./output_2010_2015.pkl\")  \n",
    "df_2016_2025 = pd.read_pickle(\"./output_2016_2025.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58ffd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_1970s, df_1980s, df_1990s, df_2000s, df_2010_2015], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d5b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'hansard_id_x': 'hansard_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(3, 'speaker_id', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaaa808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as the TWFY dataset does not contain a 'twfy_member_id' tag, we insert a column with NaN values\n",
    "\n",
    "df_2016_2025.insert(2, 'twfy_member_id', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e3944",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016_2025 = df_2016_2025.rename(columns={'hansard_id_x': 'hansard_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c915dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016_2025 = df_2016_2025[['speech_id_link', 'speaker', 'twfy_member_id', 'speaker_id',\n",
    "                             'hansard_id', 'text', 'date', 'legislature', 'chair', 'name_cld',\n",
    "                             'wikidataid', 'pageid', 'ethnicity', 'religion', 'sex', 'birth',\n",
    "                             'death', 'birthplace', 'deathplace', 'session', 'party',\n",
    "                             'constituency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6469e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure standardized column names and sort by dates\n",
    "\n",
    "df = pd.concat([df,df_2016_2025])\n",
    "df = df.sort_values(by='date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac2cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a unique ID for each speech\n",
    "\n",
    "df['id'] = df.index + 1\n",
    "df['id'] = df['id'].apply(lambda x: f'{x:07d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28709dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with the partyfact dataset to get party names\n",
    "\n",
    "partyfacts_df = pd.read_excel(\"./partyfacts_uk.xlsx\")\n",
    "partyfacts_df = partyfacts_df[[\"partyfacts_id\",\"name\"]]\n",
    "partyfacts_df = partyfacts_df.rename(columns={\"name\": \"party\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b56321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, partyfacts_df, how='left', on='party')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c5adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_45 = df[df[\"legislature\"] == 45]\n",
    "df_46 = df[df[\"legislature\"] == 46]\n",
    "df_47 = df[df[\"legislature\"] == 47] \n",
    "df_48 = df[df[\"legislature\"] == 48]\n",
    "df_49 = df[df[\"legislature\"] == 49] \n",
    "df_50 = df[df[\"legislature\"] == 50]\n",
    "df_51 = df[df[\"legislature\"] == 51] \n",
    "df_52 = df[df[\"legislature\"] == 52]\n",
    "df_53 = df[df[\"legislature\"] == 53]\n",
    "df_54 = df[df[\"legislature\"] == 54]\n",
    "df_55 = df[df[\"legislature\"] == 55]    \n",
    "df_56 = df[df[\"legislature\"] == 56]\n",
    "df_57 = df[df[\"legislature\"] == 57] \n",
    "df_58 = df[df[\"legislature\"] == 58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f0e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now one can save the dataframes for each legislature, e.g. for legislature 45:\n",
    "# This is the data that is available on the Harvard Dataverse repository\n",
    "\n",
    "df_45.to_pickle(\"./output_45.pkl\")\n",
    "df_45.to_csv(\"./output_45.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
