{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8164e26",
   "metadata": {},
   "source": [
    "By customizing this code, users can download the raw text as well as the speaker information from the UK's House of Commons parliamentary debates as available on the They Work For You online repository.\n",
    "\n",
    "In this example, the code is set to scrape data from the 1970s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1db23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load libraries\n",
    "\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import urllib.request \n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0d6a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the URL to scrape data from\n",
    "\n",
    "URL = \"https://www.theyworkforyou.com/pwdata/scrapedxml/debates/\"\n",
    "\n",
    "response = urllib.request.urlopen(URL)\n",
    "soup = BeautifulSoup(response.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daf5b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_urls = []\n",
    "for link in soup.find_all('a', href=True):\n",
    "    if '.xml' in link['href']:\n",
    "        all_urls.append(URL + link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa8c1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in all_urls:\n",
    "    if any(f\"debates{i}\" in u for i in range(1970, 1980)):  \n",
    "        filename = u.split('/')[-1]\n",
    "        urllib.request.urlretrieve(u, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c638bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = []\n",
    "\n",
    "for u in all_urls:\n",
    "    if any(f\"debates{i}\" in u for i in range(1970, 1980)):\n",
    "        filename = u.split('/')[-1]\n",
    "\n",
    "        try: \n",
    "            tree = ET.parse(filename)\n",
    "            root = tree.getroot()\n",
    "        except ET.ParseError:\n",
    "            print(\"Error parsing file:\", filename)\n",
    "            continue\n",
    "\n",
    "        for speech in root.findall('.//speech[@speakername]'):\n",
    "            name = speech.get('speakername')\n",
    "            speechid = speech.get('id')\n",
    "            hansard_membership_id = speech.get(\"hansard_membership_id\")\n",
    "            speaker_id = speech.get('speakerid')\n",
    "            text = ' '.join([p.text.strip() for p in speech.findall('.//p') if p.text])\n",
    "            final_dataset.append((speechid, name, speaker_id, hansard_membership_id, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf10a8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6a8824",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"speech_id_link\", \"speaker\", \"twfy_member_id\", \"hansard_id\", \"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ee41df",
   "metadata": {},
   "source": [
    "The resulting dataframe contains the following information, based on the scraped XML tags:\n",
    "\n",
    "- **speech_id_link**: the unique link identifier of the speech, which also contains the date in which the speech was made\n",
    "- **speaker**: the speaker of the speech as recorded in the scraped XML tags\n",
    "- **twfy_member_id**: TWFY member ID, a unique identifier for the speaker\n",
    "- **hansard_id**: Hansard ID, a unique identifier for the speaker\n",
    "- **text**: the text of the speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed198bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a pickle file (.pkl format). This has the advantage of being faster to process than a CSV file.\n",
    "\n",
    "df.to_pickle(\"uk_debates_1970_1979.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
